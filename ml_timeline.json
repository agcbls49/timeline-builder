{
	"title": {
		"media": {
			"url": "img/intro.png",
			"caption": "Machine Learning Visual Graph",
			"credit": "Wordstream: <a href='https://www.wordstream.com/blog/ws/2017/07/28/machine-learning-applications'>click to go to source</a>"
		},
		"text": {
			"headline": "History of Machine Learning in the 1950s - 2020",
			"text": "<i>A Short History of Machine Learning from Beginning to the 21st Century.</i>"
		}
	},
	"events": [
		{
			"media": {
				"url": "img/Alan_turing_header.jpg",
				"caption": "Alan Turing",
				"credit": "Wikipedia: <a href='https://en.wikipedia.org/wiki/Alan_Turing'>click to go to source</a><br/>"
			},
			"start_date": {
				"month": "10",
				"day": null,
				"year": "1950"
			},
			"text": {
				"headline": "“Turing Test”",
				"text": "Alan Turing created the essay titled “Computing Machinery and Intelligence”, this <i>introduced the</i><b> Turing Test </b><i>to ask “Can machines think?”.</i> The purpose was to test the intelligence of machines, this is carried out to see if a machine’s behavior is indistinguishable from a human’s in a text-based conversation."
			}
		},
		{
			"media": {
				"url": "img/SNARC.jpg",
				"caption": "SNARC Machine",
				"credit": "Medium Article: <a href=\"https://zahid-parvez.medium.com/history-of-ai-the-first-neural-network-computer-marvin-minsky-231c8bd58409\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1951"
			},
			"text": {
				"headline": "“SNARC”",
				"text": "<i><b>Stochastic Neural Analog Reinforcement Calculator (SNARC)</i></b> is an early neural network simulation machine designed by Marvin Minsky. It was one of the first attempts in mimicking how the human brain learn, with the use of a network of 40 simulated neurons connected with randomly changing strengths. It is <i><b>considered one of the first pioneering attempts at the field of Artificial Intelligence.</i></b>"
			}
		},
		{
			"media": {
				"url": "img/Samuel_checkers.jpg",
				"caption": "“The Father of Machine Learning”, Arthur Samuel playing checkers",
				"credit": "IBM: <a href=\"https://www.ibm.com/history/early-games\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1952"
			},
			"text": {
				"headline": "Samuel Checkers",
				"text": "This is considered one of the world’s first successful machine learning program. It improved by playing against itself until the mid-1970s, where the program achieved sufficient skill to challenge an amateur. Arthur Samuel’s work <i><b>introduced the concept of Machine Learning.</i></b>"
			}
		},
		{
			"media": {
				"url": "img/AI_darthmouth.png",
				"caption": "List of Attendees at the Conference",
				"credit": "Darthmouth: <a href=\"https://home.dartmouth.edu/about/artificial-intelligence-ai-coined-dartmouth\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1956"
			},
			"text": {
				"headline": "Artificial Intelligence",
				"text": "John McCarthy organizes the Dartmouth Conference where the term was coined. The researchers believe that <i><b>machines are capable of thinking and learning like humans.</i></b>"
			}
		},
		{
			"media": {
				"url": "img/Rosenblatt.jpg",
				"caption": "Frank Rosenblatt working on the “electronic profile analyzing computer” – a precursor to the perceptron.",
				"credit": "Cornell: <a href=\"https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1957"
			},
			"text": {
				"headline": "Rosenblatt’s Perceptron",
				"text": "The “Perceptron” is a precursor to artificial neural networks pattern recognition. Researcher were thrilled with the idea that computers could learn basic tasks. <i><b>However, its drawbacks would cause AI to face early failures.</i></b>"
			}
		},
		{
			"media": {
				"url": "img/ELIZA_conversation.png",
				"caption": "The first ever Chatbot",
				"credit": "Wikipedia: <a href=\"https://en.wikipedia.org/wiki/ELIZA\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1966"
			},
			"text": {
				"headline": "“ELIZA”",
				"text": "Joseph Weizenbaum creates “ELIZA”, a program that <i><b>simulates a conversation with a psychotherapist.</i></b> It worked by pattern-matching user input and responding with scripted lines."
			}
		},
		{
			"media": {
				"url": "img/AI_winter.png",
				"caption": "Timeline of the AI winters",
				"credit": "Research Gate: <a href='https://www.researchgate.net/figure/Timeline-of-the-AI-winters_fig1_333039347'>click to go to source</a><br/>"
			},
			"start_date": {
				"year": "1970"
			},
			"text": {
				"headline": "AI Winter",
				"text": "AI Winter is a period of reduced research interest and funding in AI. Progress slowed as AI programs failed to meet high expectations and <i><b>many consider AI as an overhyped idea at this point.</i></b>"
			}
		},
		{
			"media": {
				"url": "img/Expert_systems.png",
				"caption": "How Expert Systems Work",
				"credit": "Jaro Education: :<a href=\"https://www.jaroeducation.com/blog/what-are-expert-systems-in/\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1980"
			},
			"text": {
				"headline": "“Expert” Systems",
				"text": "AI returned to popularity with Expert Systems, programs that <i><b>stored human expert knowledge</i></b> aimed to solve problems. They were used in industries like medicine and business for decision-making."
			}
		},
		{
			"media": {
				"url": "img/Backpropagation.png",
				"caption": "Visual of Backpropagation",
				"credit": "Geeks For Geeks: <a href='https://www.geeksforgeeks.org/machine-learning/backpropagation-in-neural-network/'>click to go to source</a><br/>"
			},
			"start_date": {
				"year": "1986"
			},
			"text": {
				"headline": "Backpropagation",
				"text": "Geoffrey Hinton and others popularized the “Backpropagation Algorithm”, which made it possible to train multi-layer neural networks. <i><b>It set the stage for modern deep learning.</i></b>"
			}
		},
		{
			"media": {
				"url": "img/DeepBlue.jpg",
				"caption": "Chess champion “Garry Kasparov” playing against Deep Blue",
				"credit": "IBM: <a href=\"https://www.ibm.com/history/deep-blue\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "1997"
			},
			"text": {
				"headline": "Deep Blue",
				"text": "Deep Blue is a chess playing computer made by IBM. IBM’s Deep Blue <i><b>defeated world chess champion Garry Kasparov</i></b> in 1996."
			}
		},
		{
			"media": {
				"url": "img/DeepLearning.jpg",
				"caption": "Turing Award Recipient Geoffrey Hinton",
				"credit": "Association of Computing Machinery: <a href=\"https://awards.acm.org/award_winners/hinton_4791679\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "2006"
			},
			"text": {
				"headline": "Deep Learning Revival",
				"text": "Geoffrey Hinton reintroduces neural networks, demonstrating that they could work well with big data and GPUs. AI systems could recognize speech, images, and text far better than before. This eventually <i><b>sparked the deep learning revolution.<i></b>"
			}
		},
		{
			"media": {
				"url": "img/Waymo.png",
				"caption": "Waymo with pedestrian and cyclist",
				"credit": "Waymo: <a href='https://waymo.com/'>click to go to source</a><br/>"
			},
			"start_date": {
				"year": "2009"
			},
			"text": {
				"headline": "“Waymo”",
				"text": "Google develops a <i><b>self-driving car</i></b> which would later be a ride hailing service called Waymo. Using sensors, cameras, and machine learning, the cars could drive themselves in limited settings. This demonstrated AI’s real-world potential for transportation."
			}
		},
		{
			"media": {
				"url": "img/Jeopardy.png",
				"caption": "Participants with IBM Watson",
				"credit": "CBS News: :<a href=\"https://www.cbsnews.com/news/ibm-watson-defeats-humans-in-jeopardy/\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "2011"
			},
			"text": {
				"headline": "Winning “Jeopardy!”",
				"text": "IBM’s Watson <i><b>defeats human champions on the quiz show “Jeopardy!”.</i></b> It used natural language processing and vast knowledge databases to answer complex questions proving that machines could handle human language effectively."
			}
		},
		{
			"media": {
				"url": "img/Alexnet.png",
				"caption": "Geoffrey Hinton holding AlexNet",
				"credit": "IEEE Spectrum: <a href='https://spectrum.ieee.org/alexnet-source-code'>click to go to source</a><br>"
			},
			"start_date": {
				"year": "2012"
			},
			"text": {
				"headline": "“AlexNet”",
				"text": "AlexNet is a deep neural network for image recognition that <i><b>won the ImageNet competition.</i></b> It could classify images far better than previous systems, with the use of deep learning and GPU training. This event proved deep learning’s dominance in AI research."
			}
		},
		{
			"media": {
				"url": "https://youtu.be/W3DEJgnGZYc?si=AwWGBps0mXw8OJL6",
				"caption": "Amazon Alexa Features",
				"credit": "AI Magazine: <a href=\"https://aimagazine.com/ai-applications/how-amazon-developed-its-famous-virtual-assistant-alexa\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "2014"
			},
			"text": {
				"headline": "“Alexa”",
				"text": "Amazon releases Alexa, a <i><b>voice-activated AI assistant.</i></b> It could understand speech, answer questions, and control smart home devices. Voice AI assistants soon became common in households worldwide."
			}
		},
		{
			"media": {
				"url": "img/AlphaGo.jpg",
				"caption": "Lee Sedol and Google DeepMind's AlphaGo playing against each other",
				"credit": "GeekWire: <a href=\"https://www.geekwire.com/2016/alphago-ai-program-wins-1-million-prize-go-showdown-champion-lee-sedol/\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "2016"
			},
			"text": {
				"headline": "“AlphaGo”",
				"text": "Google DeepMind’s “AlphaGo” <i><b>defeats world champion Lee Sedol</i></b> in the <i><b>game of Go.</i></b> Go was thought too difficult for AI because of its huge number of possibilities. This victory proved the strength of reinforcement learning and deep neural networks."
			}
		},
		{
			"media": {
				"url": "img/GPT2.png",
				"caption": "GPT-2 Visual",
				"credit": "Jay Alammar: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">click to go to source</a><br>"
			},
			"start_date": {
				"year": "2018"
			},
			"text": {
				"headline": "“GPT-2”",
				"text": "OpenAI releases GPT-2, a <i><b>language model that could generate human-like text.</i></b> This demonstrated the rapid progress of natural language processing."
			}
		},
		{
			"media": {
				"url": "img/GPT3.png",
				"caption": "GPT-3 Visual",
				"credit": "NVIDIA Developer: <a href=\"https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/\">click to go to source</a><br>"
			},
			"start_date": {
				"month": "6",
				"day": null,
				"year": "2020"
			},
			"text": {
				"headline": "“GPT-3”",
				"text": "OpenAI introduces GPT-3, with 175 billion parameters, capable of writing essays, code, and conversations almost indistinguishable from humans. GPT-3 <i><b>became a major milestone in bringing AI to the mainstream.</i></b>"
			}
		},
		{
			"start_date": {
				"month": "8",
				"day": "23",
				"year": "2025"
			},
			"text": {
				"headline": "References",
				"text": "Dartmouth. (2025). Artificial intelligence (AI) coined at Dartmouth. Dartmouth College.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://home.dartmouth.edu/about/artificial-intelligence-ai-coined-dartmouth <br><br> IBM. (n.d.). The games that helped AI evolve. IBM. Retrieved August 21, 2025, from<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.ibm.com/history/early-games <br><br> Lefkowitz, M. (2019, September 25). Professor’s perceptron paved the way for AI – 60 years too soon. Cornell Chronicle.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon"
			}
		}
	]
}
